{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iWPUDrSG8Ydb"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nyJrRRNpPeZz"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import random\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "random.set_seed = 42"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1WTsTw28hmao"
      },
      "outputs": [],
      "source": [
        "path = Path('/content/drive/MyDrive/2023/VGG/VGG-AGES/FGNET/images')\n",
        "file_path = list(path.glob(r'**/*.JPG'))\n",
        "\n",
        "df = pd.DataFrame(file_path, columns=['image']).astype(str)\n",
        "\n",
        "import re\n",
        "def age(image_path):\n",
        "    x = image_path.split('.')[0].rsplit('A', 1)[1]\n",
        "    result = re.match(r'\\d+', x)\n",
        "    results = result.group(0)\n",
        "    return int(results)\n",
        "\n",
        "\n",
        "\n",
        "df['label'] = df['image'].apply(lambda x:age(x))\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "prPhR8G2hmWJ"
      },
      "outputs": [],
      "source": [
        "df.label.min(), df.label.max()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def age_map(number):\n",
        "  if number in range(0, 10):\n",
        "    age_range = '00-09'\n",
        "  elif number in range(10, 20):\n",
        "    age_range = '10-19'\n",
        "  elif number in range(20, 30):\n",
        "    age_range = '20-29'\n",
        "  elif number in range(30, 40):\n",
        "    age_range = '30-39'\n",
        "  elif number in range(40, 50):\n",
        "    age_range = '40-49'\n",
        "  elif number in range(50, 60):\n",
        "    age_range = '50-59'\n",
        "  elif number in range(60, 70):\n",
        "    age_range = '60-69'\n",
        "  return age_range"
      ],
      "metadata": {
        "id": "gHeB3Kvsc0hf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['age_group'] = df['label'].apply(lambda x:age_map(x))\n",
        "df"
      ],
      "metadata": {
        "id": "WldHwwgQcIg9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ICGFvPeiW0W"
      },
      "outputs": [],
      "source": [
        "df[\"age_group\"].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1M6WF9D5oDX"
      },
      "source": [
        "## Restructuring Directory\n",
        "\n",
        "The directory structure is not recognizable for pytorch dataloaders. <br>\n",
        "To restructure the tree so that it is readable, every file is moved under the subfolder named after its class."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def user_id(path):\n",
        "  return path.split(\"/\")[-1]\n",
        "df['image_id'] = df['image'].apply(lambda x:user_id(x))\n"
      ],
      "metadata": {
        "id": "iaHki3s7lr6S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HywZ1BdO5sRQ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sCLyl8EX51UA"
      },
      "outputs": [],
      "source": [
        "folder_path =  \"/content/drive/MyDrive/2023/VGG/VGG-AGES/FGNET/images\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_list = []\n",
        "formats = [\"JPG\", \"png\"]\n",
        "\n",
        "for subdir in os.listdir(folder_path):\n",
        "    subpath = os.path.join(folder_path, subdir)\n",
        "    if os.path.isdir(subpath):\n",
        "      for f in os.listdir(subpath):\n",
        "        filepath = os.path.join(subpath, f)\n",
        "        part = f.split(\".\")\n",
        "        if os.path.isfile(filepath) and part[-1] in formats:\n",
        "            file_list.append((filepath, f))\n",
        "\n",
        "print(len(file_list))"
      ],
      "metadata": {
        "id": "a55AkyKSvLR5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y58ENQvF56mw"
      },
      "outputs": [],
      "source": [
        "# DONT INTERRUPT WHILE RUNNING\n",
        "# SHOWS PROGRESS\n",
        "\n",
        "im_len = len(file_list)\n",
        "\n",
        "for i, (filepath, filename) in enumerate(file_list):\n",
        "    user_id = filepath.split(\"/\")[-1]\n",
        "    file_id = filename\n",
        "    class_ = df[(df[\"image_id\"] == user_id)][\"age_group\"].values[0]\n",
        "\n",
        "    new_path = os.path.join(folder_path, class_)\n",
        "    \n",
        "    if not os.path.exists(new_path):\n",
        "        os.makedirs(new_path)\n",
        "\n",
        "    # move file\n",
        "    new_path = os.path.join(new_path, filename)\n",
        "    shutil.move(filepath, new_path)\n",
        "    \n",
        "    # progress\n",
        "    prog = (20 * (i + 1)) // im_len\n",
        "    print(\"\\r[\" + \"=\"*prog + \"_\"*(20-prog) + \"]\", end=\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2PQoyLTIJRMF"
      },
      "outputs": [],
      "source": [
        "# list the classes\n",
        "!ls /content/drive/MyDrive/2023/VGG/VGG-AGES/FGNET/images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "no467nMriC4x"
      },
      "outputs": [],
      "source": [
        "# compress and save to drive for future purposes\n",
        "# ! tar -czvf faces-cleaned.tar.gz data/faces\n",
        "# ! cp faces.tar.gz /content/gdrive/My\\ Drive/project/vgg/data/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xYhoD3VWV372"
      },
      "source": [
        "## Preparation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %cd /content/drive/MyDrive/2023/VGG\n",
        "# # ! mkdir VGG-AGES\n",
        "# %cd VGG-AGES\n",
        "# ! git clone https://github.com/notshridhar/vgg-age"
      ],
      "metadata": {
        "id": "SfMPaMm3qrEz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/2023/VGG/VGG-AGES/vgg-age"
      ],
      "metadata": {
        "id": "LdAOwj4kr2pI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8AEjX8Ko9ocp"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import source.models as models\n",
        "import source.worker as worker\n",
        "import source.loader as loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BWKJrx6RPeZ9"
      },
      "outputs": [],
      "source": [
        "# the mean and std of dataset are found by running this\n",
        "# takes some time to iterate twice\n",
        "loader.find_mean_std(\"/content/drive/MyDrive/2023/VGG/VGG-AGES/FGNET/images\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "16dnpeFxMcpv"
      },
      "outputs": [],
      "source": [
        "# loader.mean and loader.std set the mean and standard deviation of the color channels of the images respectively. \n",
        "loader.random_scale = (0.8, 1.0)\n",
        "loader.mean = [0.425, 0.343, 0.314]\n",
        "loader.std  = [0.243, 0.214, 0.210]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r1unwNP5-JP_"
      },
      "outputs": [],
      "source": [
        "# Dataset Loader to feed into network\n",
        "# 20% of data is used for validation\n",
        "loaders = loader.split_loader(\"/content/drive/MyDrive/2023/VGG/VGG-AGES/FGNET/images\", valid_frac=0.2, batch_size=32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w-sl0n4mJtIy"
      },
      "outputs": [],
      "source": [
        "# pretrained weights - for convolution layers\n",
        "state = loader.load_pth(\"/content/drive/MyDrive/2023/VGG/vgg-age/weight/vgg_face_dag.pth\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_7ZLaJ5aJ8Xc"
      },
      "source": [
        "## Model initialization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wY_vlGibJ7GR"
      },
      "outputs": [],
      "source": [
        "model = models.vgg16(num_classes=8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jp7snAmjQQWw"
      },
      "outputs": [],
      "source": [
        "# pretrained vgg-face\n",
        "model.load_weights(state)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WRQkfwBD9zWg"
      },
      "outputs": [],
      "source": [
        "# gives parameter count and memory in MB\n",
        "model.memory_usage()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NxmGQ5fk-L6O"
      },
      "outputs": [],
      "source": [
        "#train for 10 epochs\n",
        "worker.train(model, loaders,lr = 0.001, epochs=10)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('checkpoint.pth')"
      ],
      "metadata": {
        "id": "uo4FwLISjZMt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# save checkpoint to drive\n",
        "!cp checkpoint.pth /content/drive/MyDrive/2023/VGG/vgg-age/checkpoint.pth"
      ],
      "metadata": {
        "id": "63RGGehGjdkc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CJAvCUZeemYc"
      },
      "source": [
        "## Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K-qqQRAVkJMq"
      },
      "outputs": [],
      "source": [
        "# to try out saved version\n",
        "\n",
        "! cp /content/drive/MyDrive/2023/VGG/VGG-AGES/vgg-age/checkpoint.pth\n",
        "\n",
        "check = loader.load_pth(\"checkpoint.pth\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DWTus0Mpk_ud"
      },
      "outputs": [],
      "source": [
        "valid_loader = loaders[1]\n",
        "conf_mat = worker.confusion_matrix(model, valid_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YAsHlirLvFgb"
      },
      "outputs": [],
      "source": [
        "for row in conf_mat:\n",
        "    for elem in row:\n",
        "        print(\"%.2f\"%(elem*100), end=\"\\t\")\n",
        "    print(\"\")\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M7bpO5ejvFZl"
      },
      "outputs": [],
      "source": [
        "# one-off accuracy\n",
        "ncls = len(conf_mat)\n",
        "tot_acc = 0\n",
        "\n",
        "for i in range(ncls):\n",
        "    \n",
        "    acc = conf_mat[i][i]\n",
        "\n",
        "    # add left\n",
        "    if i > 0:\n",
        "        acc += conf_mat[i][i-1]\n",
        "    \n",
        "    if i < ncls - 1:\n",
        "        acc += conf_mat[i][i+1]\n",
        "    \n",
        "    tot_acc += acc\n",
        "\n",
        "tot_acc = tot_acc / ncls\n",
        "print(\"%.2f\" % (tot_acc * 100))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bMIjKtBQPeaB"
      },
      "source": [
        "## Visualization\n",
        "\n",
        "The corresponding predictions and target labels are visualized along with the input images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Aue0mWRnSLN"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision.transforms as transforms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lFt1qgCwk_wf"
      },
      "outputs": [],
      "source": [
        "# get index to class mapping\n",
        "dire = \"/content/drive/MyDrive/2023/VGG/VGG-AGES/FGNET/images\"\n",
        "classes = os.listdir(dire)\n",
        "classes.sort()\n",
        "idx_to_class = {i:classes[i] for i in range(len(classes))}\n",
        "print(idx_to_class)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "model = models.vgg16(num_classes=8)\n",
        "checkpoint = torch.load(\"/content/drive/MyDrive/2023/VGG/VGG-AGES/vgg-age/checkpoint.pth\")\n",
        "model.load_state_dict(checkpoint['state_dict'])\n",
        "### now you can evaluate it\n",
        "\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "def pre_image(image_path,model):\n",
        "   img = Image.open(image_path)\n",
        "   mean = [0.425, 0.343, 0.314]\n",
        "   std = [0.243, 0.214, 0.210]\n",
        "   transform_norm = transforms.Compose([transforms.ToTensor(), \n",
        "   transforms.Resize((224,224)),transforms.Normalize(mean, std)])\n",
        "   # get normalized image\n",
        "   img_normalized = transform_norm(img).float()\n",
        "   img_normalized = img_normalized.unsqueeze_(0)\n",
        "   # input = Variable(image_tensor)\n",
        "   img_normalized = img_normalized.to(device)\n",
        "   # print(img_normalized.shape)\n",
        "   with torch.no_grad():\n",
        "      model.eval()  \n",
        "      output =model(img_normalized)\n",
        "      _, preds = torch.max(output, 1)\n",
        "      # print(output)\n",
        "      pred_class = idx_to_class[int(preds)]\n",
        "      return pred_class\n",
        "pre_image(\"/content/50.jpg\", model)"
      ],
      "metadata": {
        "id": "2iHqI8xqjVOb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "56bewRn-t3DX"
      },
      "outputs": [],
      "source": [
        "# turn model to evaluation and move to cpu\n",
        "model.eval()\n",
        "batch_size = 32\n",
        "model.to(torch.device(\"cpu\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wTT6qGqMt5yV"
      },
      "outputs": [],
      "source": [
        "# inverse transform to show images\n",
        "mean = loader.mean\n",
        "std  = loader.std\n",
        "mn_inv = [-m/s for m, s in zip(mean, std)]\n",
        "sd_inv = [1/s for s in std]\n",
        "inv_transform = transforms.Normalize(mean=mn_inv, std=sd_inv)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YyDV7MsknSBu"
      },
      "outputs": [],
      "source": [
        "with torch.no_grad():\n",
        "    for i, (input, target) in enumerate(valid_loader):\n",
        "\n",
        "        output = model(input)\n",
        "        _, preds = torch.max(output, 1)\n",
        "\n",
        "        fig=plt.figure(figsize=(15, 15))\n",
        "        columns = 4\n",
        "        rows = 5\n",
        "\n",
        "        for i in range(1, columns*rows + 1):\n",
        "\n",
        "            pred_class = idx_to_class[int(preds[i])]\n",
        "            real_class = idx_to_class[int(target[i])]\n",
        "\n",
        "            ax = fig.add_subplot(rows, columns, i)\n",
        "            ax.title.set_text(\"pred:\" + pred_class + \",\" + \"real:\" + real_class)\n",
        "            ax.axis(\"off\")\n",
        "\n",
        "            plt.imshow(inv_transform(input[i]).permute(1, 2, 0))\n",
        "\n",
        "        break\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mmul-bh1PeaD"
      },
      "source": [
        "## For cleaning gpu cache and reloading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KYR4UQe41X69"
      },
      "outputs": [],
      "source": [
        "del loaders\n",
        "del model\n",
        "del state\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KSonXhEd5no8"
      },
      "outputs": [],
      "source": [
        "import importlib\n",
        "importlib.reload(models)\n",
        "importlib.reload(worker)\n",
        "importlib.reload(loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6UHLevcSjquI"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.5"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}